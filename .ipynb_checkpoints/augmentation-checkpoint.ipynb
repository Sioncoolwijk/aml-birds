{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# call flip function\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mflip_horizontal_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mflip_horizontal_and_save\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m original_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_images/train_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# flip the original image horizontally\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m flipped_img \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTranspose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFLIP_LEFT_RIGHT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m flipped_img\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_images/train_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_flipped.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# close file\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/PIL/Image.py:2816\u001b[0m, in \u001b[0;36mImage.transpose\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(\u001b[38;5;28mself\u001b[39m, method):\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;124;03m    Transpose image (flip or rotate in 90 degree steps)\u001b[39;00m\n\u001b[1;32m   2808\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;124;03m    :returns: Returns a flipped or rotated copy of this image.\u001b[39;00m\n\u001b[1;32m   2814\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2816\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mtranspose(method))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def flip_horizontal_and_save():\n",
    "\n",
    "  # open the original image\n",
    "  for image in range(1,3926+1):\n",
    "\n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "\n",
    "        # flip the original image horizontally\n",
    "        flipped_img = original_img.transpose(method=Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        flipped_img.save(f\"train_images/train_images/{image}_flipped.jpg\")\n",
    "\n",
    "        # close file\n",
    "        original_img.close()\n",
    "        flipped_img.close()\n",
    "\n",
    "  return\n",
    "\n",
    "\n",
    "\n",
    "# call flip function\n",
    "flip_horizontal_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n6/djsdqy9538s1spkqll8wvxlh0000gn/T/ipykernel_11761/74899157.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  zoomed_img = original_img.resize((new_width, new_height), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "def zoom_and_save():\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "\n",
    "        # Open the image\n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "\n",
    "        # Get the size of the original image\n",
    "        original_width, original_height = original_img.size\n",
    "\n",
    "        # Calculate the new size after zooming in\n",
    "        new_width = int(original_width * 1.2)\n",
    "        new_height = int(original_height * 1.2)\n",
    "\n",
    "        # Resize the image to the new size\n",
    "        zoomed_img = original_img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "\n",
    "        # Calculate the crop box to maintain the original aspect ratio\n",
    "        crop_left = (new_width - original_width) // 2\n",
    "        crop_top = (new_height - original_height) // 2\n",
    "        crop_right = crop_left + original_width\n",
    "        crop_bottom = crop_top + original_height\n",
    "\n",
    "        # Crop the image\n",
    "        final_img = zoomed_img.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "\n",
    "        # Save the image\n",
    "        final_img.save(f\"train_images/train_images/{image}_zoomed.jpg\")\n",
    "\n",
    "        # close file\n",
    "        original_img.close()\n",
    "        zoomed_img.close()\n",
    "        final_img.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "zoom_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n6/djsdqy9538s1spkqll8wvxlh0000gn/T/ipykernel_11761/2591276308.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  zoomed_img = original_img.resize((new_width, new_height), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "def flip_zoom_and_save():\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "\n",
    "        # Open the image\n",
    "        original_img = Image.open(f\"train_images/train_images/{image}_flipped.jpg\")\n",
    "\n",
    "        # Get the size of the original image\n",
    "        original_width, original_height = original_img.size\n",
    "\n",
    "        # Calculate the new size after zooming in\n",
    "        new_width = int(original_width * 1.2)\n",
    "        new_height = int(original_height * 1.2)\n",
    "\n",
    "        # Resize the image to the new size\n",
    "        zoomed_img = original_img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "\n",
    "        # Calculate the crop box to maintain the original aspect ratio\n",
    "        crop_left = (new_width - original_width) // 2\n",
    "        crop_top = (new_height - original_height) // 2\n",
    "        crop_right = crop_left + original_width\n",
    "        crop_bottom = crop_top + original_height\n",
    "\n",
    "        # Crop the image\n",
    "        final_img = zoomed_img.crop((crop_left, crop_top, crop_right, crop_bottom))\n",
    "\n",
    "        # Save the image\n",
    "        final_img.save(f\"train_images/train_images/{image}_flipped_zoomed.jpg\")\n",
    "\n",
    "        # close file\n",
    "        original_img.close()\n",
    "        zoomed_img.close()\n",
    "        final_img.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "flip_zoom_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_and_save():\n",
    "\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "\n",
    "        # Load\n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "\n",
    "        # Blur\n",
    "        blurred_img = original_img.filter(ImageFilter.BoxBlur(radius=4))\n",
    "\n",
    "        # Save\n",
    "        blurred_img.save(f\"train_images/train_images/{image}_blurred.jpg\")\n",
    "\n",
    "    return\n",
    "\n",
    "blur_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_and_save():\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "\n",
    "        # Load\n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "\n",
    "        # Sharpen\n",
    "        sharpen_img = original_img.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "        # Save\n",
    "        sharpen_img.save(f\"train_images/train_images/{image}_sharpen.jpg\")\n",
    "\n",
    "    return \n",
    "\n",
    "sharpen_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_clockwise_and_save():\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "        \n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "\n",
    "        rotated_img = original_img.rotate(-10)\n",
    "\n",
    "        # Get the size of the rotated image\n",
    "        width, height = rotated_img.size\n",
    "\n",
    "        # Create a new image with a larger canvas (e.g., 1.5 times the original size)\n",
    "        new_width = int(width * 0.8)\n",
    "        new_height = int(height * 0.8)\n",
    "        fill_img = Image.new(\"RGB\", (new_width, new_height), color=\"white\")\n",
    "\n",
    "        # Calculate the position to paste the rotated image at the center\n",
    "        paste_x = (new_width - width) // 2\n",
    "        paste_y = (new_height - height) // 2\n",
    "\n",
    "        # Paste the rotated image onto the new canvas\n",
    "        fill_img.paste(rotated_img, (paste_x, paste_y))\n",
    "\n",
    "        # Save\n",
    "        fill_img.save(f\"train_images/train_images/{image}_rotated_clockwise.jpg\")\n",
    "        \n",
    "    return \n",
    "\n",
    "\n",
    "def rotate_counterclockwise_and_save():\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "        \n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "\n",
    "        rotated_img = original_img.rotate(10)\n",
    "\n",
    "        # Get the size of the rotated image\n",
    "        width, height = rotated_img.size\n",
    "\n",
    "        # Create a new image with a larger canvas (e.g., 1.5 times the original size)\n",
    "        new_width = int(width * 0.8)\n",
    "        new_height = int(height * 0.8)\n",
    "        fill_img = Image.new(\"RGB\", (new_width, new_height), color=\"white\")\n",
    "\n",
    "        # Calculate the position to paste the rotated image at the center\n",
    "        paste_x = (new_width - width) // 2\n",
    "        paste_y = (new_height - height) // 2\n",
    "\n",
    "        # Paste the rotated image onto the new canvas\n",
    "        fill_img.paste(rotated_img, (paste_x, paste_y))\n",
    "\n",
    "        # Save\n",
    "        fill_img.save(f\"train_images/train_images/{image}_rotated_counterclockwise.jpg\")\n",
    "        \n",
    "    return \n",
    "\n",
    "rotate_counterclockwise_and_save()\n",
    "rotate_clockwise_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dimensions = []\n",
    "for image in range(1,3927):\n",
    "    original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "    image_dimensions.append(original_img.size)\n",
    "\n",
    "max(image_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The biggest ratio is 500, so we could get for every image give these dimensions. But for computation sake we will do 128 by 128 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m         new_img7\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_images/final_train_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_rotated_counterclockwise.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mrescale_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m, in \u001b[0;36mrescale_and_save\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m new_img3 \u001b[38;5;241m=\u001b[39m original_img3\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m), Image\u001b[38;5;241m.\u001b[39mLANCZOS)\n\u001b[1;32m     23\u001b[0m new_img4 \u001b[38;5;241m=\u001b[39m original_img4\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m), Image\u001b[38;5;241m.\u001b[39mLANCZOS)\n\u001b[0;32m---> 24\u001b[0m new_img5 \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_img5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLANCZOS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m new_img6 \u001b[38;5;241m=\u001b[39m original_img6\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m), Image\u001b[38;5;241m.\u001b[39mLANCZOS)\n\u001b[1;32m     26\u001b[0m new_img7 \u001b[38;5;241m=\u001b[39m original_img7\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m), Image\u001b[38;5;241m.\u001b[39mLANCZOS)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/PIL/Image.py:2163\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   2161\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(size)\n\u001b[0;32m-> 2163\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2165\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Rescaling to 500x500\n",
    "def rescale_and_save():\n",
    "\n",
    "    for image in range(1,3926+1):\n",
    "\n",
    "        # Load every augmented image for the original image\n",
    "        original_img = Image.open(f\"train_images/train_images/{image}.jpg\")\n",
    "        original_img1 = Image.open(f\"train_images/train_images/{image}_zoomed.jpg\")\n",
    "        original_img2 = Image.open(f\"train_images/train_images/{image}_flipped.jpg\")\n",
    "        original_img3 = Image.open(f\"train_images/train_images/{image}_flipped_zoomed.jpg\")\n",
    "        original_img4 = Image.open(f\"train_images/train_images/{image}_blurred.jpg\")\n",
    "        original_img5 = Image.open(f\"train_images/train_images/{image}_sharpen.jpg\")\n",
    "        original_img6 = Image.open(f\"train_images/train_images/{image}_rotated_clockwise.jpg\")\n",
    "        original_img7 = Image.open(f\"train_images/train_images/{image}_rotated_counterclockwise.jpg\")\n",
    "\n",
    "        # Not taken into account the ones with expansion because changing the dimensions back gives us the original img again\n",
    "    \n",
    "        # Resize the image to the new size\n",
    "        new_img  = original_img.resize((128, 128), Image.LANCZOS)\n",
    "        new_img1 = original_img1.resize((128, 128), Image.LANCZOS)\n",
    "        new_img2 = original_img2.resize((128, 128), Image.LANCZOS)\n",
    "        new_img3 = original_img3.resize((128, 128), Image.LANCZOS)\n",
    "        new_img4 = original_img4.resize((128, 128), Image.LANCZOS)\n",
    "        new_img5 = original_img5.resize((128, 128), Image.LANCZOS)\n",
    "        new_img6 = original_img6.resize((128, 128), Image.LANCZOS)\n",
    "        new_img7 = original_img7.resize((128, 128), Image.LANCZOS)\n",
    "            \n",
    "        # Save images\n",
    "        new_img.save(f\"train_images/final_train_images/{image}.jpg\")\n",
    "        new_img1.save(f\"train_images/final_train_images/{image}_zoomed.jpg\")\n",
    "        new_img2.save(f\"train_images/final_train_images/{image}_flipped.jpg\")\n",
    "        new_img3.save(f\"train_images/final_train_images/{image}_flipped_zoomed.jpg\")\n",
    "        new_img4.save(f\"train_images/final_train_images/{image}_blurred.jpg\")\n",
    "        new_img5.save(f\"train_images/final_train_images/{image}_sharpen.jpg\")\n",
    "        new_img6.save(f\"train_images/final_train_images/{image}_rotated_clockwise.jpg\")\n",
    "        new_img7.save(f\"train_images/final_train_images/{image}_rotated_counterclockwise.jpg\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "rescale_and_save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
